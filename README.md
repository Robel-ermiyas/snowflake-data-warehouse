# ğŸ—ï¸ Modern Data Warehouse & Analytics Platform

**Author:** Robel Ermiyas Moges â€¢ **Year:** 2025  
**Architecture Overview:** [View Architecture](./Docs/ARCHITECTURE.md)  

---

## ğŸ“˜ Overview

Welcome to the **Modern Data Warehouse & Analytics Platform** repository â€” a production-ready data engineering solution built on **Snowflake**, leveraging the **Medallion Architecture** (Bronze, Silver, Gold).  
This project demonstrates **enterprise-scale data management**, **modular ELT**, and **automated orchestration** with **dbt**, **Apache Airflow**, and **Terraform**.

---

## ğŸ›ï¸ Medallion Architecture

The platform follows the **three-layer Medallion Design**, ensuring a scalable, governed, and high-performance data flow.

| Layer | Description |
|-------|--------------|
| ğŸŸ¦ **Bronze Layer** | Ingests raw data from **AWS S3** into **Snowflake** using external stages and full-load ingestion patterns. |
| ğŸŸ© **Silver Layer** | Cleanses, standardizes, and validates data using **dbt** with **incremental models**. |
| ğŸŸ¨ **Gold Layer** | Builds **business-ready** models such as **star schemas**, **fact tables**, and **analytic marts**. |
| âš™ï¸ **Orchestration** | Managed with **Apache Airflow** for automated pipeline scheduling, monitoring, and observability. |

---

## ğŸ§± Architecture Diagram

![System Architecture](./Docs/High-level-architecture.svg)

---

## ğŸ¯ Key Objectives

- **Performance:** Incremental transformations for optimized processing.  
- **Maintainability:** Modular dbt models with source-controlled SQL.  
- **Data Quality:** Automated testing and documentation pipelines.  
- **Scalability:** Cloud-native design using Snowflake and AWS S3.  
- **Observability:** Integrated monitoring and lineage tracking.

---

## ğŸš€ Enterprise Features

| Capability | Description |
|-------------|-------------|
| **â˜ï¸ Cloud-Native Integration** | Full Snowflakeâ€“AWS interoperability. |
| **ğŸ› ï¸ Infrastructure as Code** | Automated provisioning using **Terraform**. |
| **ğŸ” Orchestration** | End-to-end workflow automation with **Airflow DAGs**. |
| **ğŸ§ª Data Quality Framework** | Comprehensive dbt test coverage and validation. |
| **ğŸ” Security & Governance** | Role-based access and data lineage enforcement. |
| **ğŸ“ˆ Monitoring & Alerts** | Real-time health dashboards and notifications. |

---

## ğŸ’¡ Business Value

| Use Case | Business Impact | Implementation |
|-----------|----------------|----------------|
| **Customer 360Â°** | Unified CRM + ERP customer view | `dim_customers`, `int_unified_customers` |
| **Sales Analytics** | Real-time sales KPIs and trends | `mart_sales_performance` |
| **Customer Segmentation** | Personalized marketing & retention | `mart_customer_segmentation` |
| **Product Analytics** | Category & inventory optimization | `dim_products`, `mart_sales_trends` |

---

## âš™ï¸ Technology Stack

| Component | Tool | Purpose |
|------------|------|---------|
| **Data Warehouse** | â„ï¸ Snowflake | Central compute & storage |
| **Transformations** | ğŸ dbt | Modular SQL transformations |
| **Orchestration** | ğŸŒªï¸ Apache Airflow | Workflow scheduling |
| **Storage** | â˜ï¸ AWS S3 | Raw data lake layer |
| **Infrastructure** | ğŸ§© Terraform | IaC for Snowflake & Airflow |
| **Monitoring** | ğŸ“Š Grafana & Slack | Real-time observability |

---

## ğŸ“ Repository Structure

```
snowflake-data-warehouse/
â”œâ”€â”€ datasets/                           
â”‚   â”œâ”€â”€ source_crm /
|   |    |- csv files  
â”‚   â”œâ”€â”€ source_erp  
â”‚   |   |- csv files                
â”‚      
â”œâ”€â”€ docs/                            # ğŸ“š Comprehensive documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System architecture and design
â”‚   â”œâ”€â”€ High-level-Architecture.md   # Overview of the Medallion architecture
â”‚   â””â”€â”€ diagrams/                    # Architecture visuals and illustrations
â”‚       â”œâ”€â”€ High-level-architecture.svg
â”‚       â””â”€â”€ Data-flow-diagram.png
â”‚
â”œâ”€â”€ orchestration/                   # âš™ï¸ Pipeline orchestration & IaC
â”‚   â”œâ”€â”€ airflow/                     # Apache Airflow orchestration layer
â”‚   â”‚   â”œâ”€â”€ dags/                    # Pipeline DAGs (Bronze â†’ Silver â†’ Gold)
â”‚   â”‚   â”‚   â”œâ”€â”€ bronze_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ silver_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gold_pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ full_pipeline.py
â”‚   â”‚   â”‚   â””â”€â”€ monitoring/          # Data quality & reliability checks
â”‚   â”‚   â”œâ”€â”€ plugins/                 # Custom Airflow operators
â”‚   â”‚   â”‚   â”œâ”€â”€ snowflake_operators.py
â”‚   â”‚   â”‚   â””â”€â”€ dbt_operators.py
â”‚   â”‚   â”œâ”€â”€ config/                  # Airflow configuration templates
â”‚   â”‚   â”‚   â”œâ”€â”€ airflow.cfg.example
â”‚   â”‚   â”‚   â””â”€â”€ variables.json
â”‚   â”‚   â””â”€â”€ docker/                  # Dockerized Airflow setup
â”‚   â”‚       â”œâ”€â”€ Dockerfile
â”‚   â”‚       â”œâ”€â”€ docker-compose.yml
â”‚   â”‚       â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ monitoring/                  # System observability & alerting
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline_health.json
â”‚   â”‚   â”‚   â””â”€â”€ data_quality.json
â”‚   â”‚   â”œâ”€â”€ alerts/
â”‚   â”‚   â”‚   â”œâ”€â”€ slack_notifications.py
â”‚   â”‚   â”‚   â””â”€â”€ email_templates.py
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â”œâ”€â”€ health_checks.py
â”‚   â”‚       â””â”€â”€ backup_scripts.py
â”‚   â””â”€â”€ terraform/                   # Infrastructure as Code (IaC)
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ outputs.tf
â”‚
â”œâ”€â”€ scripts/                         # ğŸª¶ Data transformation & processing layers
â”‚   â”œâ”€â”€ bronze/                      # ğŸŸ¦ Bronze Layer â€” Raw data ingestion
â”‚   â”‚   â”œâ”€â”€ 00_strategy_documentation.md  # Strategy documentation
â”‚   â”‚   â”œâ”€â”€ 01_file_formats.sql           # Snowflake file formats
â”‚   â”‚   â”œâ”€â”€ 02_external_stages.sql        # S3 stage configurations
â”‚   â”‚   â”œâ”€â”€ 03_table_ddl.sql              # Raw table definitions
â”‚   â”‚   â”œâ”€â”€ 04_load_procedure.sql         # Data ingestion logic
â”‚   â”‚   â”œâ”€â”€ 05_validation_procedures.sql  # Data validation scripts
â”‚   â”‚   â””â”€â”€ 06_execution_script.sql       # Bronze layer execution
â”‚   â”‚
â”‚   â”œâ”€â”€ silver/                     # ğŸŸ© Silver Layer â€” Data cleaning & modeling
â”‚   â”‚   â””â”€â”€ dbt/
â”‚   â”‚       â”œâ”€â”€ dbt_project.yml
â”‚   â”‚       â”œâ”€â”€ packages.yml
â”‚   â”‚       â”œâ”€â”€ models/
â”‚   â”‚       â”‚   â”œâ”€â”€ staging/
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ crm/
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_customers.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_products.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_sales.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ erp/
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_erp_customers.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_erp_locations.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ stg_erp_categories.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”œâ”€â”€ macros/
â”‚   â”‚       â”‚   â”œâ”€â”€ incremental_strategy.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ utils.sql
â”‚   â”‚       â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”œâ”€â”€ tests/
â”‚   â”‚       â”‚   â””â”€â”€ data_quality/
â”‚   â”‚       â””â”€â”€ config/
â”‚   â”‚
â”‚   â”œâ”€â”€ gold/                       # ğŸŸ¨ Gold Layer â€” Business-ready analytics
â”‚   â”‚   â””â”€â”€ dbt/
â”‚   â”‚       â”œâ”€â”€ dbt_project.yml
â”‚   â”‚       â”œâ”€â”€ packages.yml
â”‚   â”‚       â”œâ”€â”€ models/
â”‚   â”‚       â”‚   â”œâ”€â”€ marts/
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ dim_customers.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ dim_products.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ dim_dates.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ fct_sales.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ sales/
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ mart_sales_performance.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ mart_sales_trends.sql
â”‚   â”‚       â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ marketing/
â”‚   â”‚       â”‚   â”‚       â”œâ”€â”€ mart_customer_segmentation.sql
â”‚   â”‚       â”‚   â”‚       â”œâ”€â”€ mart_customer_acquisition.sql
â”‚   â”‚       â”‚   â”‚       â””â”€â”€ schema.yml
â”‚   â”‚       â”‚   â””â”€â”€ staging/
â”‚   â”‚       â”‚       â””â”€â”€ int_unified_customers.sql
â”‚   â”‚       â”œâ”€â”€ macros/
â”‚   â”‚       â”‚   â”œâ”€â”€ surrogate_keys.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ customer_segmentation.sql
â”‚   â”‚       â”‚   â”œâ”€â”€ financial_metrics.sql
â”‚   â”‚       â”‚   â””â”€â”€ schema.yml
â”‚   â”‚       â”œâ”€â”€ tests/
â”‚   â”‚       â”‚   â”œâ”€â”€ referential_integrity/
â”‚   â”‚       â”‚   â””â”€â”€ business_logic/
â”‚   â”‚       â””â”€â”€ config/
â”‚
â”œâ”€â”€ config/                         # âš™ï¸ Configuration templates
â”‚   â”œâ”€â”€ terraform.tfvars.example     # Terraform variables
â”‚   â”œâ”€â”€ environment.example          # Environment variables
â”‚   â””â”€â”€ dbt-profiles.example         # dbt connection profiles
â”‚
â””â”€â”€ README.md                        # ğŸ§­ Project overview and documentation
```

---

## ğŸš€ Quick Start

### Prerequisites
- Snowflake Account (ACCOUNTADMIN privileges)
- AWS Account with S3 Access
- Terraform â‰¥ v1.0
- Docker & Docker Compose
- Python â‰¥ 3.8

### Deployment Steps

```bash
# 1. Clone Repository
git clone https://github.com/Robel-ermiyas/snowflake-data-warehouse.git
cd snowflake-data-warehouse

# 2. Configure Environment
cp config/environment.example .env
# Edit .env with Snowflake and AWS credentials

# 3. Deploy Infrastructure
cd orchestration/terraform/
terraform init
terraform apply -var-file="../../config/terraform.tfvars"

# 4. Start Airflow Orchestration
cd ../airflow/docker/
docker-compose up -d
```

Access Airflow at **http://localhost:8080** and trigger `full_pipeline`.

---

## ğŸ“Š Data Model Design

**Star Schema Components**
- Dimensions: `dim_customers`, `dim_products`, `dim_dates`
- Facts: `fct_sales`
- Marts: `mart_sales_performance`, `mart_customer_segmentation`

**Core Business KPIs**
- **Average Order Value (AOV)** â€” Revenue per transaction  
- **Customer Lifetime Value (LTV)** â€” Profitability per customer  
- **Sales Growth Rate** â€” Month-over-month performance  
- **Customer Acquisition Cost (CAC)** â€” Marketing efficiency  

---

## ğŸ” Security & Governance

**Role-Based Access**
| Role | Responsibility |
|------|----------------|
| `ROBEL_LOADER` | Bronze ingestion |
| `ROBEL_TRANSFORMER` | Transformations |
| `ROBEL_ANALYST` | Reporting access |
| `ROBEL_PIPELINE` | Pipeline orchestration |

**Data Protection**
- AES-256 encryption at rest  
- TLS 1.2+ in transit  
- Network-restricted Snowflake access policies  
- Comprehensive query & access audit logs  

---

## ğŸ“ˆ Monitoring & Operations

| Metric | Target |
|---------|--------|
| Pipeline Reliability | 99.9% uptime |
| Data Freshness | < 4 hours |
| Data Quality | 99.5% test pass rate |
| Query Performance | < 30 seconds |

**Alerting Channels**
- Slack: Real-time incident alerts  
- Email: Daily data quality summaries  
- Grafana: Performance dashboards  

---


## ğŸ¤ Contributing
We welcome contributions!  

**Development Flow**
1. Fork the repository  
2. Create a feature branch  
3. Commit and push changes  
4. Open a Pull Request  

**Coding Standards**
- Follow dbt + SQL style guides  
- Include unit and integration tests  
- Update documentation for new modules  

---

## ğŸ“„ License

Licensed under the **MIT License**. 

---

## ğŸ“ Contact & Resources

- ğŸ“˜ **Documentation:** [`/docs`](./docs/)  
- ğŸ› **Issues:** [GitHub Issues](../../issues)  
- ğŸ’¬ **Discussions:** [GitHub Discussions](../../discussions)

## â˜• Stay Connected

Letâ€™s connect! 

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/robel-ermiyas)

---
---

## ğŸ‘¥ Acknowledgments

Built by **Robel Ermiyas Moges (2025)** 

Special thanks to:
- **dbt Labs** â€” for the transformation framework  
- **Apache Airflow** â€” for powerful orchestration  
- **Snowflake** â€” for scalable cloud warehousing  
- **AWS** â€” for reliable data lake infrastructure  

> *â€œData is the new oil â€” but only if you can refine it.â€*  
> â€” *Modern Data Refinement at Scale* ğŸš€
